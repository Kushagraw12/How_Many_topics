{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LDA&SA",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7Ss8Kc/UxBgNS5z9F/GGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siftee150/How_Many_topics/blob/master/Copy_of_LDA%26SA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjqj5t35nHJN"
      },
      "source": [
        " \n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "from wordcloud import WordCloud\n",
        "import gensim\n",
        "from gensim.models import CoherenceModel, LdaModel\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj0K2e0lnR7z"
      },
      "source": [
        "rx_dict = {\n",
        "    'keys': re.compile(r'Key: (?P<keys>.*)\\n'),\n",
        "    'medline': re.compile(r'Medline: (?P<medline>\\d+)\\n'),\n",
        "    'authors': re.compile(r'Authors: (?P<authors>.*)\\n'),\n",
        "    'title': re.compile(r'Title: (?P<title>.*)'),\n",
        "    'citation': re.compile(r'Citation: (?P<citation>.*)'),\n",
        "    'type': re.compile(r'Type: (?P<type>.*)'),\n",
        "    'genes': re.compile(r'Genes: (?P<genes>.*)'),\n",
        "    'abstract': re.compile(r'Abstract: (?P<abstract>.*)'),\n",
        "    'end':re.compile(r'-------------------')\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vZ3SSFMykI3"
      },
      "source": [
        "def _findregex(line):\n",
        "  for key,rx in rx_dict.items():\n",
        "    match=rx.search(line)\n",
        "    if match:\n",
        "      return key,match\n",
        "  return None,None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLIkKCrlzZyw"
      },
      "source": [
        "def parse_file(filepath):\n",
        "  data=[]\n",
        "  keyval='-'\n",
        "  medval='-'\n",
        "  author_val='-'\n",
        "  title_val='-'\n",
        "  citation_val='-'\n",
        "  type_val='-'\n",
        "  genes_val='-'\n",
        "  abstract_val='-'\n",
        "\n",
        "  with open(filepath,'r') as file_object:\n",
        "    line=file_object.readline()\n",
        "    while line:\n",
        "      key,match=_findregex(line)\n",
        "      if key =='keys':\n",
        "        keyval=match.group('keys')\n",
        "      if key =='medline':\n",
        "        medval=match.group('medline')\n",
        "      if key =='authors':\n",
        "        author_val=match.group('authors')\n",
        "      if key =='title':\n",
        "        title_val=match.group('title')\n",
        "      if key =='citation':\n",
        "        citation_val=match.group('citation')\n",
        "      if key =='type':\n",
        "        type_val=match.group('type')\n",
        "      if key =='genes':\n",
        "        genes_val=match.group('genes')\n",
        "      if key =='abstract':\n",
        "        abstract_val=match.group('abstract')\n",
        "      if key=='end':\n",
        "        row = {\n",
        "          'Key': keyval,\n",
        "          'Medline': medval,\n",
        "          'Authors': author_val,\n",
        "          'Title': title_val,\n",
        "          'Citation': citation_val,\n",
        "          'Type': type_val,\n",
        "          'Genes': genes_val,\n",
        "          'Abstract': abstract_val ,\n",
        "          }\n",
        "        data.append(row)\n",
        "      line=file_object.readline()\n",
        "    data=pd.DataFrame(data)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqmJGQiX5m9x"
      },
      "source": [
        "Finaldata=parse_file('/content/textfile.txt')\n",
        "print(Finaldata.head(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRf82DNuo6Hb"
      },
      "source": [
        " \n",
        "def remove_punct(text):\n",
        "  return text.translate(str.maketrans('', '', string.punctuation))\n",
        "def remove_stopword(text):\n",
        "  STOPWORD = set(stopwords.words('english'))\n",
        "  return \" \".join([word for word in str(text).split() if word not in STOPWORD])\n",
        "lemmatise = WordNetLemmatizer()\n",
        "def lemmatize_word(text):\n",
        "    return \" \".join([lemmatise.lemmatize(word) for word in text.split()])\n",
        "ps = PorterStemmer()\n",
        "def stem_doc(text):\n",
        "    return \" \".join([ps.stem(word) for word in text.split()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vRLk_FQse2o"
      },
      "source": [
        "Finaldata[\"Title_cleaned\"]=Finaldata[\"Title\"].str.lower()\n",
        "Finaldata[\"Title_cleaned\"]=Finaldata[\"Title_cleaned\"].apply(lambda text:remove_punct(text))\n",
        "Finaldata[\"Title_cleaned\"]=Finaldata[\"Title_cleaned\"].apply(lambda text:remove_stopword(text))\n",
        "Finaldata[\"Title_cleaned\"]=Finaldata[\"Title_cleaned\"].apply(lambda text:lemmatize_word(text))\n",
        "Finaldata[\"Title_cleaned\"]=Finaldata[\"Title_cleaned\"].apply(lambda text:stem_doc(text))\n",
        "Finaldata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuGtvBITW_nu"
      },
      "source": [
        "Finaldata=Finaldata.drop(['Citation', 'Genes', 'Type'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmzScJbYr36-"
      },
      "source": [
        "Finaldata[\"Abstract_cleaned\"]=Finaldata[\"Abstract\"].str.lower()\n",
        "Finaldata[\"Abstract_cleaned\"]=Finaldata[\"Abstract_cleaned\"].apply(lambda text:remove_punct(text))\n",
        "Finaldata[\"Abstract_cleaned\"]=Finaldata[\"Abstract_cleaned\"].apply(lambda text:remove_stopword(text))\n",
        "Finaldata[\"Abstract_cleaned\"]=Finaldata[\"Abstract_cleaned\"].apply(lambda text:lemmatize_word(text))\n",
        "Finaldata[\"Abstract_cleaned\"]=Finaldata[\"Abstract_cleaned\"].apply(lambda text:stem_doc(text))\n",
        "Finaldata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGAfwUNQhHd4"
      },
      "source": [
        "Finaldata[\"FinalText\"]=Finaldata[\"Title_cleaned\"]+\" \"+Finaldata[\"Abstract_cleaned\"]\n",
        "Finaldata[\"FinalText\"]=Finaldata[\"FinalText\"].apply(lambda text:nltk.word_tokenize(text))\n",
        "Finaldata[\"FinalText\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk-co9JVlBXJ"
      },
      "source": [
        "Finaldata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhFssjcpIlk5"
      },
      "source": [
        "total_word_count={}\n",
        "for row in Finaldata[\"FinalText\"]:\n",
        "  for word in row:\n",
        "    if word not in total_word_count.keys():\n",
        "      total_word_count[word]=1\n",
        "    else:\n",
        "      total_word_count[word]+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1ZDkxL9JC5C"
      },
      "source": [
        "total_word_count\n",
        "#max(total_word_count,key=total_word_count.get)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paKoiZdLp738"
      },
      "source": [
        "wordcloud=WordCloud(width=800,height=800,background_color=\"white\",min_font_size=10).generate_from_frequencies(total_word_count)\n",
        "plt.figure(figsize = (8, 8)) \n",
        "plt.imshow(wordcloud) \n",
        "plt.axis(\"off\") \n",
        "plt.tight_layout(pad = 0) \n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bac-DpkhyfCu"
      },
      "source": [
        "lists=list(total_word_count.items())[:100]\n",
        "#keys=total_word_count.keys()\n",
        "#values=total_word_count.values()\n",
        "plt.rcParams['figure.figsize']=(20,10)\n",
        "for i in range(len(lists)):\n",
        "  plt.bar(lists[i][0],lists[i][1])\n",
        "plt.ylim(0,3000)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6QvnkSn5_dn"
      },
      "source": [
        "Finaldata.to_csv('final_text.csv',index=False,header=False,\n",
        "                 columns=['Key','Authors','FinalText'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z63zwmsxWYj3"
      },
      "source": [
        "#using lda algorithm on preprocessed data\n",
        "dictionary=gensim.corpora.Dictionary(Finaldata[\"FinalText\"])\n",
        "#dictionary\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPPe16g_gNhG"
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in Finaldata[\"FinalText\"]]\n",
        "bow_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA2rcqfHg1nW"
      },
      "source": [
        "bow_doc_4972 = bow_corpus[4972]\n",
        "for i in range(len(bow_doc_4972)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4972[i][0],dictionary[bow_doc_4972[i][0]],bow_doc_4972[i][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51QVWLXZhGf4"
      },
      "source": [
        "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
        "                                   num_topics = 10, \n",
        "                                   id2word = dictionary,                                    \n",
        "                                   passes = 10,\n",
        "                                   workers = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSXy-PgYhYtS"
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc1DZBAE0rrO"
      },
      "source": [
        "for index, score in sorted(lda_model[bow_corpus[4972]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9O4cApBCQLr"
      },
      "source": [
        "bow_corpus[4972]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gQeRTIj8NfB"
      },
      "source": [
        "print('\\nPerplexity: ', lda_model.log_perplexity(bow_corpus)) \n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=Finaldata[\"FinalText\"], dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjyl9G4z_9t6"
      },
      "source": [
        "def compute_coherence_value(dictionary, corpus, texts, start,limit,step):\n",
        "    coherence_value = []\n",
        "    model_list = []\n",
        "    for total_topics in range(start, limit, step):\n",
        "        model = LdaModel(corpus=corpus, num_topics=total_topics,id2word=dictionary,passes=10)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_value.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkY78a4CFEkl"
      },
      "source": [
        "model_list, coherence_values = compute_coherence_value(dictionary=dictionary, corpus=bow_corpus, texts=Finaldata[\"FinalText\"], start=1, limit=101, step=5)\n",
        "coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jNGMLoqMzTX"
      },
      "source": [
        "limit=101; start=1; step=5;\n",
        "x = range(start, limit, step)\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Net number of Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XRTkrXuQrze"
      },
      "source": [
        "for notopics, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", notopics, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0I5l-UKIomo"
      },
      "source": [
        "optimal_model = model_list[18]\n",
        "for idx, topic in optimal_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI9vbgk6JEYH"
      },
      "source": [
        "for t in range(optimal_model.num_topics):\n",
        "  plt.figure(figsize = (8, 8))\n",
        "  wordcloud=WordCloud(width=800,height=800,background_color=\"black\",min_font_size=10).generate_from_frequencies(dict(optimal_model.show_topic(2, 200)))\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "#optimal_model.show_topic(1, 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmDvo1To_1fB"
      },
      "source": [
        "subdata=[];\n",
        "for i in range(0,5):\n",
        "  subdata.append(Finaldata[\"FinalText\"].sample(frac=0.8))\n",
        "#for k in range(1,101,5):\n",
        "for sample in subdata:\n",
        "  sub_dictionary=gensim.corpora.Dictionary(sample)\n",
        "  sub_bow_corpus = [sub_dictionary.doc2bow(doc) for doc in sample]\n",
        "  model_list, coherence_values = compute_coherence_value(dictionary=sub_dictionary, corpus=sub_bow_corpus,texts=sample, start=1, limit=101, step=5)\n",
        "  limit=101; start=1; step=5;\n",
        "  x = range(start, limit, step)\n",
        "  plt.figure(figsize=(12,12))\n",
        "  plt.plot(x, coherence_values)\n",
        "  plt.xlabel(\"Net number of Topics\")\n",
        "  plt.ylabel(\"Coherence score\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5n-6tUsekQE"
      },
      "source": [
        "def jaccard_index(list1,list2):\n",
        "  s1=set(list1);\n",
        "  s2=set(list2)\n",
        "  return float(len(s1.intersection(s2))) / float(len(s1.union(s2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR49ta87sm2x"
      },
      "source": [
        "def hungarian method():\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42ogJ1cLosxk"
      },
      "source": [
        "def agree(S0,Sx):\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRZQRY0hmTBP"
      },
      "source": [
        "for i in range(0,51):\n",
        "  subdata.append(Finaldata[\"FinalText\"].sample(frac=0.8))\n",
        "for k in range(10,20,10):\n",
        "  lda_model_base =  gensim.models.LdaMulticore(bow_corpus,num_topics = 10,id2word = dictionary,passes = 10,workers = 2)\n",
        "  x=lda_model_base.show_topics(num_words=10)\n",
        "  S0={}\n",
        "  for topic,word in x:\n",
        "    S0[topic]=re.sub('[^A-Za-z ]+','',word)\n",
        "  for sample in subdata:\n",
        "    sub_dictionary=gensim.corpora.Dictionary(sample)\n",
        "    sub_bow_corpus = [sub_dictionary.doc2bow(doc) for doc in sample]\n",
        "    lda_model_sub =  gensim.models.LdaMulticore(sub_bow_corpus,num_topics = k,id2word =sub_dictionary,passes = 10,workers = 2)\n",
        "    y=lda_model_base.show_topics(num_words=10)\n",
        "    Sx={}\n",
        "    for topic,word in x:\n",
        "      Sx[topic]=re.sub('[^A-Za-z ]+','',word)\n",
        "print(Sx)\n",
        "print(S0)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}