{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA_BlogAuthorshipCorpus_khushnuma.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_ShVfmolnA6"
      },
      "source": [
        "## **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy7RnwvuLAnC",
        "outputId": "b1732f42-44fd-4830-9d3f-414e62c2822a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mounting my google drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dACoh75-MH4a"
      },
      "source": [
        "!cp 'drive/My Drive/Datasets/archive.zip' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjOlFBBCLdPA",
        "outputId": "a734b909-f8b4-4c1d-96b3-415b0de74cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# unzipping the dataset\n",
        "\n",
        "!unzip archive.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  archive.zip\n",
            "  inflating: blogtext.csv            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLaY7-fBMt84"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(\"blogtext.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slundJ6RM8ML",
        "outputId": "0e98cbdc-905b-4a5d-8583-4b79000eca81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>14,May,2004</td>\n",
              "      <td>Info has been found (+/- 100 pages,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>13,May,2004</td>\n",
              "      <td>These are the team members:   Drewe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>In het kader van kernfusie op aarde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>testing!!!  testing!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>11,June,2004</td>\n",
              "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                               text\n",
              "0  2059027  ...             Info has been found (+/- 100 pages,...\n",
              "1  2059027  ...             These are the team members:   Drewe...\n",
              "2  2059027  ...             In het kader van kernfusie op aarde...\n",
              "3  2059027  ...                   testing!!!  testing!!!          \n",
              "4  3581210  ...               Thanks to Yahoo!'s Toolbar I can ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jSMWXE2lwEI"
      },
      "source": [
        "## **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzwQ2PI4l8C1"
      },
      "source": [
        "### **removing unnecessary columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "333XF3GxM-jG"
      },
      "source": [
        "train = train[['topic','text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nu8_JCYNZAZ",
        "outputId": "c61e2c59-c37f-463e-9142-375dc3177bb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Student</td>\n",
              "      <td>Info has been found (+/- 100 pages,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Student</td>\n",
              "      <td>These are the team members:   Drewe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Student</td>\n",
              "      <td>In het kader van kernfusie op aarde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Student</td>\n",
              "      <td>testing!!!  testing!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               topic                                               text\n",
              "0            Student             Info has been found (+/- 100 pages,...\n",
              "1            Student             These are the team members:   Drewe...\n",
              "2            Student             In het kader van kernfusie op aarde...\n",
              "3            Student                   testing!!!  testing!!!          \n",
              "4  InvestmentBanking               Thanks to Yahoo!'s Toolbar I can ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r72QmIg_mF9d"
      },
      "source": [
        "### **steps**:\n",
        "* Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
        "* Words that have fewer than 3 characters are removed.\n",
        "* All stopwords are removed.\n",
        "* Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
        "* Words are stemmed — words are reduced to their root form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMjk-SVrl4NQ",
        "outputId": "1803feda-d0fe-48f1-ee46-9f9a2c547c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(13)\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5wyZWCd14mF"
      },
      "source": [
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pLgcIFO1Wvz"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nFtJ-151Yb3",
        "outputId": "55972230-0faa-40e2-9283-e0e2d4fdd2ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "doc_sample = train['text'][0]\n",
        "print('original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original document: \n",
            "['', '', '', '', '', '', '', '', '', '', '', 'Info', 'has', 'been', 'found', '(+/-', '100', 'pages,', 'and', '4.5', 'MB', 'of', '.pdf', 'files)', 'Now', 'i', 'have', 'to', 'wait', 'untill', 'our', 'team', 'leader', 'has', 'processed', 'it', 'and', 'learns', 'html.', '', '', '', '', '', '', '', '', '']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['info', 'page', 'file', 'wait', 'until', 'team', 'leader', 'process', 'learn', 'html']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgGmXJGX1K0s"
      },
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvonwjNu2Kqc"
      },
      "source": [
        "train['clean_doc'] = train['text'].progress_map(preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goVHeadjwFQ8",
        "outputId": "9b1555af-da26-4edf-c699-9fb571ee2d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Student</td>\n",
              "      <td>Info has been found (+/- 100 pages,...</td>\n",
              "      <td>[info, page, file, wait, until, team, leader, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Student</td>\n",
              "      <td>These are the team members:   Drewe...</td>\n",
              "      <td>[team, member, drew, laag, urllink, mail, ruiy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Student</td>\n",
              "      <td>In het kader van kernfusie op aarde...</td>\n",
              "      <td>[kader, kernfusi, aard, maak, eigen, waterstof...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Student</td>\n",
              "      <td>testing!!!  testing!!!</td>\n",
              "      <td>[test, test]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
              "      <td>[thank, yahoo, toolbar, captur, url, popup, me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>I had an interesting conversation...</td>\n",
              "      <td>[interest, convers, morn, talk, korean, money,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Somehow Coca-Cola has a way of su...</td>\n",
              "      <td>[coca, cola, sum, thing, earli, flagship, jing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>If anything, Korea is a country o...</td>\n",
              "      <td>[korea, countri, extrem, base, think, come, ko...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Take a read of this news article ...</td>\n",
              "      <td>[read, news, articl, urllink, joongang, ilbo, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>I surf the English news sites a l...</td>\n",
              "      <td>[surf, english, news, sit, look, tidbit, korea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               topic  ...                                          clean_doc\n",
              "0            Student  ...  [info, page, file, wait, until, team, leader, ...\n",
              "1            Student  ...  [team, member, drew, laag, urllink, mail, ruiy...\n",
              "2            Student  ...  [kader, kernfusi, aard, maak, eigen, waterstof...\n",
              "3            Student  ...                                       [test, test]\n",
              "4  InvestmentBanking  ...  [thank, yahoo, toolbar, captur, url, popup, me...\n",
              "5  InvestmentBanking  ...  [interest, convers, morn, talk, korean, money,...\n",
              "6  InvestmentBanking  ...  [coca, cola, sum, thing, earli, flagship, jing...\n",
              "7  InvestmentBanking  ...  [korea, countri, extrem, base, think, come, ko...\n",
              "8  InvestmentBanking  ...  [read, news, articl, urllink, joongang, ilbo, ...\n",
              "9  InvestmentBanking  ...  [surf, english, news, sit, look, tidbit, korea...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBksRUbU0gmQ"
      },
      "source": [
        "train = train.drop(['text'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8dXs4cd0vuV",
        "outputId": "ae203f95-822d-436d-e759-433311589d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>clean_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Student</td>\n",
              "      <td>[info, page, file, wait, until, team, leader, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Student</td>\n",
              "      <td>[team, member, drew, laag, urllink, mail, ruiy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Student</td>\n",
              "      <td>[kader, kernfusi, aard, maak, eigen, waterstof...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Student</td>\n",
              "      <td>[test, test]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>[thank, yahoo, toolbar, captur, url, popup, me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>[interest, convers, morn, talk, korean, money,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>[coca, cola, sum, thing, earli, flagship, jing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>[korea, countri, extrem, base, think, come, ko...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>[read, news, articl, urllink, joongang, ilbo, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>[surf, english, news, sit, look, tidbit, korea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               topic                                          clean_doc\n",
              "0            Student  [info, page, file, wait, until, team, leader, ...\n",
              "1            Student  [team, member, drew, laag, urllink, mail, ruiy...\n",
              "2            Student  [kader, kernfusi, aard, maak, eigen, waterstof...\n",
              "3            Student                                       [test, test]\n",
              "4  InvestmentBanking  [thank, yahoo, toolbar, captur, url, popup, me...\n",
              "5  InvestmentBanking  [interest, convers, morn, talk, korean, money,...\n",
              "6  InvestmentBanking  [coca, cola, sum, thing, earli, flagship, jing...\n",
              "7  InvestmentBanking  [korea, countri, extrem, base, think, come, ko...\n",
              "8  InvestmentBanking  [read, news, articl, urllink, joongang, ilbo, ...\n",
              "9  InvestmentBanking  [surf, english, news, sit, look, tidbit, korea..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3tcGQ2JwIgE"
      },
      "source": [
        "train.to_csv('/content/drive/My Drive/preprocessed_blog.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKWGBXsMrJd7"
      },
      "source": [
        "### **Exploratory Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qJqSjjdwsPG"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv(\"/content/drive/My Drive/preprocessed_blog.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu7gYqEI2Gu7",
        "outputId": "622e8e3c-c232-47fd-df5d-393430ada8c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>topic</th>\n",
              "      <th>clean_doc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Student</td>\n",
              "      <td>['info', 'page', 'file', 'wait', 'until', 'tea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Student</td>\n",
              "      <td>['team', 'member', 'drew', 'laag', 'urllink', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Student</td>\n",
              "      <td>['kader', 'kernfusi', 'aard', 'maak', 'eigen',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Student</td>\n",
              "      <td>['test', 'test']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>['thank', 'yahoo', 'toolbar', 'captur', 'url',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>['interest', 'convers', 'morn', 'talk', 'korea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>['coca', 'cola', 'sum', 'thing', 'earli', 'fla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>['korea', 'countri', 'extrem', 'base', 'think'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>['read', 'news', 'articl', 'urllink', 'joongan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>['surf', 'english', 'news', 'sit', 'look', 'ti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                          clean_doc\n",
              "0           0  ...  ['info', 'page', 'file', 'wait', 'until', 'tea...\n",
              "1           1  ...  ['team', 'member', 'drew', 'laag', 'urllink', ...\n",
              "2           2  ...  ['kader', 'kernfusi', 'aard', 'maak', 'eigen',...\n",
              "3           3  ...                                   ['test', 'test']\n",
              "4           4  ...  ['thank', 'yahoo', 'toolbar', 'captur', 'url',...\n",
              "5           5  ...  ['interest', 'convers', 'morn', 'talk', 'korea...\n",
              "6           6  ...  ['coca', 'cola', 'sum', 'thing', 'earli', 'fla...\n",
              "7           7  ...  ['korea', 'countri', 'extrem', 'base', 'think'...\n",
              "8           8  ...  ['read', 'news', 'articl', 'urllink', 'joongan...\n",
              "9           9  ...  ['surf', 'english', 'news', 'sit', 'look', 'ti...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16QY1p5I47XV"
      },
      "source": [
        "from ast import literal_eval\n",
        "train['clean_doc'] = train['clean_doc'].map(literal_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IRwNSb6DH8"
      },
      "source": [
        "train.to_pickle('/content/drive/My Drive/preprocessed_blog.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP9_dskt6YJt"
      },
      "source": [
        "train = pd.read_pickle('/content/drive/My Drive/preprocessed_blog.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Jdlrgd5DeE",
        "outputId": "6c8ae33c-d60e-4161-cb01-9aae68726614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train['clean_doc'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['info', 'page', 'file', 'wait', 'until', 'team', 'leader', 'process', 'learn', 'html']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61-CPELWN2sE",
        "outputId": "8ad7d754-5088-490b-e5ca-3be12b72cc53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "train.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    681284\n",
              "topic         681284\n",
              "clean_doc     681284\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-yFt82qOHm6",
        "outputId": "e7bab6f3-3cdc-4b2c-aee3-f7906908672b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "train['topic'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "indUnk                     251015\n",
              "Student                    153903\n",
              "Technology                  42055\n",
              "Arts                        32449\n",
              "Education                   29633\n",
              "Communications-Media        20140\n",
              "Internet                    16006\n",
              "Non-Profit                  14700\n",
              "Engineering                 11653\n",
              "Law                          9040\n",
              "Publishing                   7753\n",
              "Science                      7269\n",
              "Government                   6907\n",
              "Consulting                   5862\n",
              "Religion                     5235\n",
              "Fashion                      4851\n",
              "Marketing                    4769\n",
              "Advertising                  4676\n",
              "BusinessServices             4500\n",
              "Banking                      4049\n",
              "Chemicals                    3928\n",
              "Telecommunications           3891\n",
              "Accounting                   3832\n",
              "Military                     3128\n",
              "Museums-Libraries            3096\n",
              "Sports-Recreation            3038\n",
              "HumanResources               3010\n",
              "RealEstate                   2870\n",
              "Transportation               2326\n",
              "Manufacturing                2272\n",
              "Biotech                      2234\n",
              "Tourism                      1942\n",
              "LawEnforcement-Security      1878\n",
              "Architecture                 1638\n",
              "InvestmentBanking            1292\n",
              "Automotive                   1244\n",
              "Agriculture                  1235\n",
              "Construction                 1093\n",
              "Environment                   592\n",
              "Maritime                      280\n",
              "Name: topic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvyr0-cEAg7e"
      },
      "source": [
        "## **Bag of Words on the clean docs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx-0J-QECnJB"
      },
      "source": [
        "### **dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYvpb7XmwfTA"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(train['clean_doc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PPy95qmAwGi",
        "outputId": "5185c7c8-6292-4210-b057-ef41b2c86e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "for i in range(20):\n",
        "    print(i, dictionary[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 file\n",
            "1 html\n",
            "2 info\n",
            "3 leader\n",
            "4 learn\n",
            "5 page\n",
            "6 process\n",
            "7 team\n",
            "8 until\n",
            "9 wait\n",
            "10 aalder\n",
            "11 bryan\n",
            "12 drew\n",
            "13 laag\n",
            "14 mail\n",
            "15 member\n",
            "16 ruiyu\n",
            "17 urllink\n",
            "18 aard\n",
            "19 abl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgcv6wdcCCNo"
      },
      "source": [
        "### **Filter out tokens that appear in**\n",
        "* less than 15 documents (absolute number) or\n",
        "* more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
        "* after the above two steps, keep only the first 100000 most frequent tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9wesOyRBYav"
      },
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icpEa7vwCM9q",
        "outputId": "56ab0a4f-a4bc-4e90-b73a-77d1cb37e549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "for i in range(20):\n",
        "    print(i, dictionary[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 file\n",
            "1 html\n",
            "2 info\n",
            "3 leader\n",
            "4 learn\n",
            "5 page\n",
            "6 process\n",
            "7 team\n",
            "8 until\n",
            "9 wait\n",
            "10 bryan\n",
            "11 drew\n",
            "12 mail\n",
            "13 member\n",
            "14 urllink\n",
            "15 abl\n",
            "16 absolut\n",
            "17 accident\n",
            "18 accomplish\n",
            "19 accord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baTcY5oNCi6i"
      },
      "source": [
        "### **Gensim doc2bow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jptc-lmCV3G"
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in train['clean_doc']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOJPHrt5EBil"
      },
      "source": [
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUwsMzbkC-C9",
        "outputId": "30d50a4b-8ab6-4762-86d4-3c1f509a775b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('Preprocessed Text')\n",
        "print(train['clean_doc'][500])\n",
        "for i in range(len(bow_corpus[500])):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_corpus[500][i][0], \n",
        "                                                    dictionary[bow_corpus[500][i][0]], \n",
        "                                                    bow_corpus[500][i][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessed Text\n",
            "['monday', 'start', 'possibl', 'process', 'buy', 'place', 'realtor', 'paper', 'sign', 'go', 'commit', 'scari', 'thing', 'idea', 'home', 'ownership', 'sign', 'away', 'life', 'year', 'good', 'idea', 'financi', 'mental', 'good', 'singl', 'girlfriend', 'buy', 'place', 'friend', 'richmond', 'buy', 'hous', 'think', 'ball', 'home', 'ownership', 'deal', 'hous', 'deal', 'person', 'mow', 'prune', 'roof', 'replac', 'window', 'wash', 'bare', 'handl', 'keep', 'room', 'apart', 'order', 'shape', 'imagin', 'letter', 'neighbor', 'concern', 'jungl', 'certain', 'grow', 'outsid', 'home', 'condo', 'condo', 'sound', 'good', 'like', 'apart', 'paint', 'wall', 'deduct', 'condo', 'search', 'hard', 'begin', 'stag', 'see', 'person', 'bunch', 'onlin', 'catch', 'think', 'wait', 'perfect', 'fall', 'picki', 'open', 'mind', 'tell', 'realtor', 'interest', 'citi', 'properti', 'construct', 'want', 'live', 'wear', 'wise', 'place', 'nice', 'tri', 'sell', 'place', 'realtor', 'take', 'note', 'check', 'ring', 'attract', 'marri', 'mean', 'love', 'win', 'person', 'bright', 'smile', 'blog', 'want', 'relationship', 'blog', 'want', 'littl', 'guess', 'friend', 'expect', 'good', 'friend', 'get', 'marri', 'summer', 'tell', 'singl', 'girl', 'claim', 'singl', 'watch', 'felt', 'year', 'poof', 'get', 'marri', 'relationship', 'phobia', 'haven', 'expect', 'year', 'unexpect', 'readi', 'commit', 'readi', 'commit', 'condo', 'sure']\n",
            "Word 6 (\"process\") appears 1 time.\n",
            "Word 9 (\"wait\") appears 1 time.\n",
            "Word 44 (\"apart\") appears 2 time.\n",
            "Word 58 (\"attract\") appears 1 time.\n",
            "Word 70 (\"begin\") appears 1 time.\n",
            "Word 131 (\"certain\") appears 1 time.\n",
            "Word 137 (\"check\") appears 1 time.\n",
            "Word 146 (\"citi\") appears 1 time.\n",
            "Word 171 (\"construct\") appears 1 time.\n",
            "Word 289 (\"expect\") appears 2 time.\n",
            "Word 343 (\"friend\") appears 3 time.\n",
            "Word 360 (\"get\") appears 2 time.\n",
            "Word 361 (\"girl\") appears 1 time.\n",
            "Word 366 (\"go\") appears 1 time.\n",
            "Word 369 (\"good\") appears 4 time.\n",
            "Word 384 (\"handl\") appears 1 time.\n",
            "Word 386 (\"hard\") appears 1 time.\n",
            "Word 387 (\"haven\") appears 1 time.\n",
            "Word 404 (\"home\") appears 3 time.\n",
            "Word 413 (\"hous\") appears 2 time.\n",
            "Word 426 (\"idea\") appears 2 time.\n",
            "Word 455 (\"interest\") appears 1 time.\n",
            "Word 494 (\"life\") appears 1 time.\n",
            "Word 496 (\"like\") appears 1 time.\n",
            "Word 500 (\"littl\") appears 1 time.\n",
            "Word 501 (\"live\") appears 1 time.\n",
            "Word 526 (\"mean\") appears 1 time.\n",
            "Word 565 (\"neighbor\") appears 1 time.\n",
            "Word 574 (\"note\") appears 1 time.\n",
            "Word 587 (\"open\") appears 1 time.\n",
            "Word 589 (\"order\") appears 1 time.\n",
            "Word 597 (\"ownership\") appears 2 time.\n",
            "Word 621 (\"place\") appears 4 time.\n",
            "Word 637 (\"possibl\") appears 1 time.\n",
            "Word 658 (\"properti\") appears 1 time.\n",
            "Word 691 (\"readi\") appears 2 time.\n",
            "Word 721 (\"room\") appears 1 time.\n",
            "Word 745 (\"see\") appears 1 time.\n",
            "Word 749 (\"sell\") appears 1 time.\n",
            "Word 757 (\"shape\") appears 1 time.\n",
            "Word 792 (\"sound\") appears 1 time.\n",
            "Word 806 (\"start\") appears 1 time.\n",
            "Word 842 (\"sure\") appears 1 time.\n",
            "Word 852 (\"take\") appears 1 time.\n",
            "Word 861 (\"tell\") appears 2 time.\n",
            "Word 870 (\"thing\") appears 1 time.\n",
            "Word 887 (\"tri\") appears 1 time.\n",
            "Word 906 (\"unexpect\") appears 1 time.\n",
            "Word 930 (\"want\") appears 3 time.\n",
            "Word 937 (\"wear\") appears 1 time.\n",
            "Word 948 (\"window\") appears 1 time.\n",
            "Word 953 (\"wise\") appears 1 time.\n",
            "Word 1006 (\"fall\") appears 1 time.\n",
            "Word 1031 (\"person\") appears 3 time.\n",
            "Word 1050 (\"sign\") appears 2 time.\n",
            "Word 1067 (\"year\") appears 3 time.\n",
            "Word 1094 (\"think\") appears 2 time.\n",
            "Word 1122 (\"imagin\") appears 1 time.\n",
            "Word 1135 (\"onlin\") appears 1 time.\n",
            "Word 1165 (\"commit\") appears 3 time.\n",
            "Word 1175 (\"girlfriend\") appears 1 time.\n",
            "Word 1177 (\"guess\") appears 1 time.\n",
            "Word 1220 (\"paper\") appears 1 time.\n",
            "Word 1241 (\"marri\") appears 3 time.\n",
            "Word 1283 (\"financi\") appears 1 time.\n",
            "Word 1295 (\"perfect\") appears 1 time.\n",
            "Word 1309 (\"watch\") appears 1 time.\n",
            "Word 1319 (\"blog\") appears 2 time.\n",
            "Word 1321 (\"bright\") appears 1 time.\n",
            "Word 1326 (\"deal\") appears 2 time.\n",
            "Word 1336 (\"keep\") appears 1 time.\n",
            "Word 1344 (\"outsid\") appears 1 time.\n",
            "Word 1352 (\"singl\") appears 3 time.\n",
            "Word 1356 (\"wall\") appears 1 time.\n",
            "Word 1379 (\"letter\") appears 1 time.\n",
            "Word 1380 (\"love\") appears 1 time.\n",
            "Word 1399 (\"buy\") appears 3 time.\n",
            "Word 1499 (\"nice\") appears 1 time.\n",
            "Word 1651 (\"replac\") appears 1 time.\n",
            "Word 1667 (\"bunch\") appears 1 time.\n",
            "Word 1734 (\"away\") appears 1 time.\n",
            "Word 1757 (\"summer\") appears 1 time.\n",
            "Word 1766 (\"concern\") appears 1 time.\n",
            "Word 2091 (\"felt\") appears 1 time.\n",
            "Word 2102 (\"scari\") appears 1 time.\n",
            "Word 2122 (\"ball\") appears 1 time.\n",
            "Word 2229 (\"search\") appears 1 time.\n",
            "Word 2286 (\"catch\") appears 1 time.\n",
            "Word 2299 (\"mind\") appears 1 time.\n",
            "Word 2359 (\"relationship\") appears 2 time.\n",
            "Word 2460 (\"grow\") appears 1 time.\n",
            "Word 2481 (\"smile\") appears 1 time.\n",
            "Word 2497 (\"stag\") appears 1 time.\n",
            "Word 2694 (\"bare\") appears 1 time.\n",
            "Word 2849 (\"claim\") appears 1 time.\n",
            "Word 2878 (\"wash\") appears 1 time.\n",
            "Word 2898 (\"mental\") appears 1 time.\n",
            "Word 3026 (\"jungl\") appears 1 time.\n",
            "Word 3105 (\"ring\") appears 1 time.\n",
            "Word 3394 (\"paint\") appears 1 time.\n",
            "Word 3969 (\"monday\") appears 1 time.\n",
            "Word 4552 (\"win\") appears 1 time.\n",
            "Word 4662 (\"picki\") appears 1 time.\n",
            "Word 7332 (\"richmond\") appears 1 time.\n",
            "Word 7472 (\"phobia\") appears 1 time.\n",
            "Word 7554 (\"condo\") appears 4 time.\n",
            "Word 7586 (\"deduct\") appears 1 time.\n",
            "Word 7587 (\"mow\") appears 1 time.\n",
            "Word 7588 (\"poof\") appears 1 time.\n",
            "Word 7589 (\"prune\") appears 1 time.\n",
            "Word 7590 (\"realtor\") appears 3 time.\n",
            "Word 7591 (\"roof\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij941AsfEfbF"
      },
      "source": [
        "### **TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okRakP44DQl7"
      },
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "corpus_tfidf = tfidf[bow_corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxOG1mnMEx6E",
        "outputId": "2455aef9-65ff-4323-b766-ec28b9e52eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "corpus_tfidf[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.3298123436868355),\n",
              " (1, 0.3558990332081455),\n",
              " (2, 0.3585221676972244),\n",
              " (3, 0.3338008779074768),\n",
              " (4, 0.21615377189705884),\n",
              " (5, 0.25751837545870365),\n",
              " (6, 0.29673467081264626),\n",
              " (7, 0.27147372926271435),\n",
              " (8, 0.46649600154635723),\n",
              " (9, 0.17942237454157067)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaxrFjxoFLOU"
      },
      "source": [
        "## **Running LDA using Bag of Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5AX2KQ1FCFa"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=1, workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQjK_WDGLQc2",
        "outputId": "e76820bb-788f-43a9-a556-da0c9c449829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.026*\"go\" + 0.015*\"good\" + 0.013*\"play\" + 0.013*\"like\" + 0.011*\"time\" + 0.011*\"night\" + 0.009*\"watch\" + 0.009*\"movi\" + 0.009*\"today\" + 0.009*\"come\"\n",
            "Topic: 1 \n",
            "Words: 0.023*\"go\" + 0.022*\"like\" + 0.015*\"haha\" + 0.015*\"today\" + 0.010*\"yeah\" + 0.010*\"come\" + 0.010*\"say\" + 0.009*\"home\" + 0.009*\"gonna\" + 0.008*\"time\"\n",
            "Topic: 2 \n",
            "Words: 0.010*\"like\" + 0.009*\"look\" + 0.007*\"go\" + 0.006*\"walk\" + 0.006*\"littl\" + 0.005*\"time\" + 0.005*\"come\" + 0.005*\"night\" + 0.005*\"head\" + 0.005*\"drink\"\n",
            "Topic: 3 \n",
            "Words: 0.811*\"nbsp\" + 0.008*\"quotejil\" + 0.006*\"quotejoel\" + 0.002*\"know\" + 0.002*\"think\" + 0.002*\"time\" + 0.002*\"like\" + 0.002*\"go\" + 0.001*\"kendra\" + 0.001*\"want\"\n",
            "Topic: 4 \n",
            "Words: 0.026*\"work\" + 0.014*\"time\" + 0.012*\"go\" + 0.012*\"week\" + 0.009*\"need\" + 0.009*\"think\" + 0.008*\"year\" + 0.008*\"thing\" + 0.008*\"today\" + 0.007*\"good\"\n",
            "Topic: 5 \n",
            "Words: 0.104*\"urllink\" + 0.017*\"blog\" + 0.015*\"post\" + 0.013*\"read\" + 0.011*\"book\" + 0.008*\"site\" + 0.008*\"link\" + 0.007*\"write\" + 0.006*\"pictur\" + 0.006*\"page\"\n",
            "Topic: 6 \n",
            "Words: 0.011*\"peopl\" + 0.008*\"say\" + 0.007*\"bush\" + 0.006*\"american\" + 0.006*\"state\" + 0.005*\"presid\" + 0.005*\"polit\" + 0.005*\"right\" + 0.005*\"think\" + 0.005*\"countri\"\n",
            "Topic: 7 \n",
            "Words: 0.020*\"love\" + 0.013*\"life\" + 0.008*\"heart\" + 0.007*\"world\" + 0.007*\"live\" + 0.006*\"know\" + 0.006*\"come\" + 0.006*\"word\" + 0.005*\"time\" + 0.005*\"feel\"\n",
            "Topic: 8 \n",
            "Words: 0.010*\"year\" + 0.005*\"team\" + 0.005*\"student\" + 0.005*\"time\" + 0.005*\"class\" + 0.005*\"school\" + 0.004*\"group\" + 0.003*\"say\" + 0.003*\"citi\" + 0.003*\"game\"\n",
            "Topic: 9 \n",
            "Words: 0.029*\"know\" + 0.026*\"like\" + 0.025*\"think\" + 0.019*\"want\" + 0.017*\"thing\" + 0.016*\"feel\" + 0.015*\"time\" + 0.014*\"peopl\" + 0.012*\"go\" + 0.011*\"friend\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idYv1GCMFVv-",
        "outputId": "8e01e9ae-be2f-4f90-9e3c-20c5fabfc228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
        "\n",
        "# preprocessing and to dictionary\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "\n",
        "# topic scores\n",
        "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.6574388742446899\t Topic: 0.011*\"peopl\" + 0.008*\"say\" + 0.007*\"bush\" + 0.006*\"american\" + 0.006*\"state\"\n",
            "Score: 0.20921683311462402\t Topic: 0.104*\"urllink\" + 0.017*\"blog\" + 0.015*\"post\" + 0.013*\"read\" + 0.011*\"book\"\n",
            "Score: 0.01667087711393833\t Topic: 0.026*\"work\" + 0.014*\"time\" + 0.012*\"go\" + 0.012*\"week\" + 0.009*\"need\"\n",
            "Score: 0.01666918583214283\t Topic: 0.029*\"know\" + 0.026*\"like\" + 0.025*\"think\" + 0.019*\"want\" + 0.017*\"thing\"\n",
            "Score: 0.01666867919266224\t Topic: 0.010*\"year\" + 0.005*\"team\" + 0.005*\"student\" + 0.005*\"time\" + 0.005*\"class\"\n",
            "Score: 0.016667895019054413\t Topic: 0.020*\"love\" + 0.013*\"life\" + 0.008*\"heart\" + 0.007*\"world\" + 0.007*\"live\"\n",
            "Score: 0.016667209565639496\t Topic: 0.026*\"go\" + 0.015*\"good\" + 0.013*\"play\" + 0.013*\"like\" + 0.011*\"time\"\n",
            "Score: 0.016666879877448082\t Topic: 0.811*\"nbsp\" + 0.008*\"quotejil\" + 0.006*\"quotejoel\" + 0.002*\"know\" + 0.002*\"think\"\n",
            "Score: 0.0166668388992548\t Topic: 0.010*\"like\" + 0.009*\"look\" + 0.007*\"go\" + 0.006*\"walk\" + 0.006*\"littl\"\n",
            "Score: 0.016666730865836143\t Topic: 0.023*\"go\" + 0.022*\"like\" + 0.015*\"haha\" + 0.015*\"today\" + 0.010*\"yeah\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RjkjMyd89jd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}